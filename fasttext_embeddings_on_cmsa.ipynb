{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11335 1260 12595\n",
      "                                                text   category\n",
      "0           Trailer late ah parthavanga like podunga  Positive \n",
      "1         Move pathutu vanthu trailer pakurvnga yaru  Positive \n",
      "2           Puthupetai dhanush  ah yarellam pathinga  Positive \n",
      "3   Dhanush oda character ,puthu sa erukay , mass ta  Positive \n",
      "4   vera level ippa pesungada mokka nu thalaivaaaaaa  Positive \n",
      "          id                                               text\n",
      "0  ta_sent_1         Yarayellam FDFS ppga ippove ready agitinga\n",
      "1  ta_sent_2  Ennada viswasam mersal sarkar madhri time la l...\n",
      "2  ta_sent_3  yuvan vera level ya .... valuable script. SK i...\n",
      "3  ta_sent_4  70 vayasulayum thanoda rasigargala sandhosapad...\n",
      "4  ta_sent_5      all the best anna...Telugu makkal selvan fans\n"
     ]
    }
   ],
   "source": [
    "lang = \"tamil\"\n",
    "\n",
    "df_train = pd.read_csv(\"data1/\"+lang+\"/\"+lang+\"_train.tsv\",sep=\"\\t\")\n",
    "df_dev = pd.read_csv(\"data1/\"+lang+\"/\"+lang+\"_dev.tsv\",sep=\"\\t\")\n",
    "df_test = pd.read_csv(\"data1/\"+lang+\"/\"+lang+\"_test.tsv\",sep=\"\\t\")\n",
    "\n",
    "df_train = df_train.dropna()\n",
    "df_dev = df_dev.dropna()\n",
    "df_test = df_test.dropna()\n",
    "\n",
    "print(len(df_train),len(df_dev),len(df_train)+len(df_dev))\n",
    "print(df_train.head())\n",
    "\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = list(df_train['text'].values)\n",
    "dev_sentences = list(df_dev['text'].values)\n",
    "\n",
    "train_labels = list(df_train['category'].values)\n",
    "dev_labels = list(df_dev['category'].values)\n",
    "\n",
    "test_sentences = list(df_test['text'].values)\n",
    "\n",
    "\n",
    "total_sentences = []\n",
    "total_sentences.extend(train_sentences)\n",
    "total_sentences.extend(dev_sentences)\n",
    "total_sentences.extend(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = open(\"tamil_total_input_sentences.txt\",\"w+\",encoding='utf-8')\n",
    "\n",
    "for line in total_sentences:\n",
    "    fout.write(line+\"\\n\")\n",
    "fout.close()\n",
    "\n",
    "import sentencepiece as spm\n",
    "spm.SentencePieceTrainer.train(input=\"tamil_total_input_sentences.txt\", model_prefix='t_m')\n",
    "sp = spm.SentencePieceProcessor(model_file='t_m.model')\n",
    "tokenized_file = sp.encode(total_sentences, out_type=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "for i in range(5,50,5):\n",
    "    model_ft = FastText(size=256, window=5, min_count=1,  sentences=tokenized_file, iter=i, sg=1)\n",
    "    model_ft.save(\"model_ft_\"+str(i))\n",
    "    del model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3_env)",
   "language": "python",
   "name": "py3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
